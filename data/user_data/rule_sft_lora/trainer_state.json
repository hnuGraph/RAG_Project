{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9947765525246663,
  "eval_steps": 500,
  "global_step": 1290,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.023215322112594312,
      "grad_norm": 1.6087851524353027,
      "learning_rate": 7.751937984496124e-06,
      "loss": 0.9242,
      "step": 10
    },
    {
      "epoch": 0.046430644225188625,
      "grad_norm": 1.3422409296035767,
      "learning_rate": 1.5503875968992248e-05,
      "loss": 0.8912,
      "step": 20
    },
    {
      "epoch": 0.06964596633778293,
      "grad_norm": 1.414637804031372,
      "learning_rate": 2.3255813953488374e-05,
      "loss": 0.7074,
      "step": 30
    },
    {
      "epoch": 0.09286128845037725,
      "grad_norm": 0.39439231157302856,
      "learning_rate": 3.1007751937984497e-05,
      "loss": 0.5115,
      "step": 40
    },
    {
      "epoch": 0.11607661056297155,
      "grad_norm": 0.3955601155757904,
      "learning_rate": 3.875968992248062e-05,
      "loss": 0.4714,
      "step": 50
    },
    {
      "epoch": 0.13929193267556586,
      "grad_norm": 0.4346162676811218,
      "learning_rate": 4.651162790697675e-05,
      "loss": 0.4582,
      "step": 60
    },
    {
      "epoch": 0.1625072547881602,
      "grad_norm": 0.36038798093795776,
      "learning_rate": 5.426356589147287e-05,
      "loss": 0.4453,
      "step": 70
    },
    {
      "epoch": 0.1857225769007545,
      "grad_norm": 0.346187025308609,
      "learning_rate": 6.201550387596899e-05,
      "loss": 0.4346,
      "step": 80
    },
    {
      "epoch": 0.2089378990133488,
      "grad_norm": 0.466849684715271,
      "learning_rate": 6.976744186046513e-05,
      "loss": 0.425,
      "step": 90
    },
    {
      "epoch": 0.2321532211259431,
      "grad_norm": 0.4348369538784027,
      "learning_rate": 7.751937984496124e-05,
      "loss": 0.4212,
      "step": 100
    },
    {
      "epoch": 0.2553685432385374,
      "grad_norm": 0.38185128569602966,
      "learning_rate": 8.527131782945736e-05,
      "loss": 0.4286,
      "step": 110
    },
    {
      "epoch": 0.2785838653511317,
      "grad_norm": 0.33757099509239197,
      "learning_rate": 9.30232558139535e-05,
      "loss": 0.4141,
      "step": 120
    },
    {
      "epoch": 0.3017991874637261,
      "grad_norm": 0.3060663342475891,
      "learning_rate": 9.99998169477592e-05,
      "loss": 0.41,
      "step": 130
    },
    {
      "epoch": 0.3250145095763204,
      "grad_norm": 0.5563586354255676,
      "learning_rate": 9.997785230060993e-05,
      "loss": 0.4086,
      "step": 140
    },
    {
      "epoch": 0.3482298316889147,
      "grad_norm": 0.4301122725009918,
      "learning_rate": 9.991929563254914e-05,
      "loss": 0.412,
      "step": 150
    },
    {
      "epoch": 0.371445153801509,
      "grad_norm": 0.37724417448043823,
      "learning_rate": 9.982418981670414e-05,
      "loss": 0.4064,
      "step": 160
    },
    {
      "epoch": 0.3946604759141033,
      "grad_norm": 0.471075177192688,
      "learning_rate": 9.969260448619924e-05,
      "loss": 0.4002,
      "step": 170
    },
    {
      "epoch": 0.4178757980266976,
      "grad_norm": 0.3442654609680176,
      "learning_rate": 9.952463598317285e-05,
      "loss": 0.4028,
      "step": 180
    },
    {
      "epoch": 0.4410911201392919,
      "grad_norm": 0.3839269280433655,
      "learning_rate": 9.932040728823929e-05,
      "loss": 0.4046,
      "step": 190
    },
    {
      "epoch": 0.4643064422518862,
      "grad_norm": 0.3712212145328522,
      "learning_rate": 9.90800679304465e-05,
      "loss": 0.3978,
      "step": 200
    },
    {
      "epoch": 0.4875217643644806,
      "grad_norm": 0.3352227210998535,
      "learning_rate": 9.880379387779637e-05,
      "loss": 0.4,
      "step": 210
    },
    {
      "epoch": 0.5107370864770748,
      "grad_norm": 0.3753910958766937,
      "learning_rate": 9.849178740840701e-05,
      "loss": 0.3882,
      "step": 220
    },
    {
      "epoch": 0.5339524085896692,
      "grad_norm": 0.34433165192604065,
      "learning_rate": 9.814427696241196e-05,
      "loss": 0.4037,
      "step": 230
    },
    {
      "epoch": 0.5571677307022634,
      "grad_norm": 0.3832452595233917,
      "learning_rate": 9.77615169747043e-05,
      "loss": 0.4055,
      "step": 240
    },
    {
      "epoch": 0.5803830528148578,
      "grad_norm": 0.29956164956092834,
      "learning_rate": 9.734378768864843e-05,
      "loss": 0.3943,
      "step": 250
    },
    {
      "epoch": 0.6035983749274522,
      "grad_norm": 0.5496599674224854,
      "learning_rate": 9.689139495089575e-05,
      "loss": 0.4016,
      "step": 260
    },
    {
      "epoch": 0.6268136970400464,
      "grad_norm": 0.29796257615089417,
      "learning_rate": 9.640466998745456e-05,
      "loss": 0.3939,
      "step": 270
    },
    {
      "epoch": 0.6500290191526408,
      "grad_norm": 0.5730403661727905,
      "learning_rate": 9.588396916117799e-05,
      "loss": 0.3908,
      "step": 280
    },
    {
      "epoch": 0.673244341265235,
      "grad_norm": 0.5464263558387756,
      "learning_rate": 9.532967371084778e-05,
      "loss": 0.3935,
      "step": 290
    },
    {
      "epoch": 0.6964596633778294,
      "grad_norm": 0.45640379190444946,
      "learning_rate": 9.474218947204459e-05,
      "loss": 0.3944,
      "step": 300
    },
    {
      "epoch": 0.7196749854904236,
      "grad_norm": 0.2653352618217468,
      "learning_rate": 9.41219465800096e-05,
      "loss": 0.3858,
      "step": 310
    },
    {
      "epoch": 0.742890307603018,
      "grad_norm": 0.3220648765563965,
      "learning_rate": 9.346939915471453e-05,
      "loss": 0.3927,
      "step": 320
    },
    {
      "epoch": 0.7661056297156124,
      "grad_norm": 0.4052039086818695,
      "learning_rate": 9.278502496837116e-05,
      "loss": 0.3957,
      "step": 330
    },
    {
      "epoch": 0.7893209518282066,
      "grad_norm": 0.36614343523979187,
      "learning_rate": 9.206932509562325e-05,
      "loss": 0.3887,
      "step": 340
    },
    {
      "epoch": 0.812536273940801,
      "grad_norm": 0.5542151927947998,
      "learning_rate": 9.13228235466774e-05,
      "loss": 0.3836,
      "step": 350
    },
    {
      "epoch": 0.8357515960533952,
      "grad_norm": 0.3442068099975586,
      "learning_rate": 9.05460668836413e-05,
      "loss": 0.3866,
      "step": 360
    },
    {
      "epoch": 0.8589669181659896,
      "grad_norm": 0.31440022587776184,
      "learning_rate": 8.97396238203501e-05,
      "loss": 0.39,
      "step": 370
    },
    {
      "epoch": 0.8821822402785838,
      "grad_norm": 0.3565092980861664,
      "learning_rate": 8.890408480597436e-05,
      "loss": 0.3834,
      "step": 380
    },
    {
      "epoch": 0.9053975623911782,
      "grad_norm": 0.28074517846107483,
      "learning_rate": 8.80400615927139e-05,
      "loss": 0.3892,
      "step": 390
    },
    {
      "epoch": 0.9286128845037724,
      "grad_norm": 0.2864561080932617,
      "learning_rate": 8.71481867878944e-05,
      "loss": 0.3823,
      "step": 400
    },
    {
      "epoch": 0.9518282066163668,
      "grad_norm": 0.4083094596862793,
      "learning_rate": 8.622911339079464e-05,
      "loss": 0.3874,
      "step": 410
    },
    {
      "epoch": 0.9750435287289612,
      "grad_norm": 0.3479746878147125,
      "learning_rate": 8.528351431454351e-05,
      "loss": 0.3886,
      "step": 420
    },
    {
      "epoch": 0.9982588508415554,
      "grad_norm": 0.3167734444141388,
      "learning_rate": 8.43120818934367e-05,
      "loss": 0.3802,
      "step": 430
    },
    {
      "epoch": 1.0214741729541497,
      "grad_norm": 0.46771711111068726,
      "learning_rate": 8.33155273760339e-05,
      "loss": 0.3826,
      "step": 440
    },
    {
      "epoch": 1.044689495066744,
      "grad_norm": 0.38420242071151733,
      "learning_rate": 8.229458040440783e-05,
      "loss": 0.3593,
      "step": 450
    },
    {
      "epoch": 1.0679048171793384,
      "grad_norm": 0.3626375198364258,
      "learning_rate": 8.124998847992586e-05,
      "loss": 0.3693,
      "step": 460
    },
    {
      "epoch": 1.0911201392919327,
      "grad_norm": 0.42204204201698303,
      "learning_rate": 8.018251641595604e-05,
      "loss": 0.3641,
      "step": 470
    },
    {
      "epoch": 1.114335461404527,
      "grad_norm": 0.42623192071914673,
      "learning_rate": 7.909294577789766e-05,
      "loss": 0.3852,
      "step": 480
    },
    {
      "epoch": 1.1375507835171212,
      "grad_norm": 0.3936684727668762,
      "learning_rate": 7.79820743109465e-05,
      "loss": 0.3659,
      "step": 490
    },
    {
      "epoch": 1.1607661056297156,
      "grad_norm": 0.4884268045425415,
      "learning_rate": 7.68507153560142e-05,
      "loss": 0.3602,
      "step": 500
    },
    {
      "epoch": 1.18398142774231,
      "grad_norm": 0.5062832832336426,
      "learning_rate": 7.56996972542285e-05,
      "loss": 0.3651,
      "step": 510
    },
    {
      "epoch": 1.2071967498549043,
      "grad_norm": 0.4153916537761688,
      "learning_rate": 7.452986274045115e-05,
      "loss": 0.3652,
      "step": 520
    },
    {
      "epoch": 1.2304120719674985,
      "grad_norm": 0.43446245789527893,
      "learning_rate": 7.334206832625719e-05,
      "loss": 0.3716,
      "step": 530
    },
    {
      "epoch": 1.2536273940800928,
      "grad_norm": 0.4352872967720032,
      "learning_rate": 7.213718367282737e-05,
      "loss": 0.3659,
      "step": 540
    },
    {
      "epoch": 1.2768427161926872,
      "grad_norm": 0.33469876646995544,
      "learning_rate": 7.09160909542129e-05,
      "loss": 0.3744,
      "step": 550
    },
    {
      "epoch": 1.3000580383052815,
      "grad_norm": 0.46412888169288635,
      "learning_rate": 6.96796842114387e-05,
      "loss": 0.3661,
      "step": 560
    },
    {
      "epoch": 1.323273360417876,
      "grad_norm": 0.3842778205871582,
      "learning_rate": 6.842886869791809e-05,
      "loss": 0.3683,
      "step": 570
    },
    {
      "epoch": 1.34648868253047,
      "grad_norm": 0.3585832715034485,
      "learning_rate": 6.716456021665824e-05,
      "loss": 0.3616,
      "step": 580
    },
    {
      "epoch": 1.3697040046430644,
      "grad_norm": 0.358644038438797,
      "learning_rate": 6.58876844497414e-05,
      "loss": 0.3712,
      "step": 590
    },
    {
      "epoch": 1.3929193267556588,
      "grad_norm": 0.32805290818214417,
      "learning_rate": 6.45991762805732e-05,
      "loss": 0.3638,
      "step": 600
    },
    {
      "epoch": 1.416134648868253,
      "grad_norm": 0.5142149329185486,
      "learning_rate": 6.329997910939394e-05,
      "loss": 0.3638,
      "step": 610
    },
    {
      "epoch": 1.4393499709808473,
      "grad_norm": 0.33649829030036926,
      "learning_rate": 6.199104416255425e-05,
      "loss": 0.3684,
      "step": 620
    },
    {
      "epoch": 1.4625652930934416,
      "grad_norm": 0.33343705534935,
      "learning_rate": 6.0673329796060686e-05,
      "loss": 0.3627,
      "step": 630
    },
    {
      "epoch": 1.485780615206036,
      "grad_norm": 0.4191264808177948,
      "learning_rate": 5.934780079390124e-05,
      "loss": 0.3681,
      "step": 640
    },
    {
      "epoch": 1.5089959373186304,
      "grad_norm": 0.3609813451766968,
      "learning_rate": 5.801542766166453e-05,
      "loss": 0.3651,
      "step": 650
    },
    {
      "epoch": 1.5322112594312247,
      "grad_norm": 0.42753294110298157,
      "learning_rate": 5.66771859159699e-05,
      "loss": 0.3592,
      "step": 660
    },
    {
      "epoch": 1.555426581543819,
      "grad_norm": 0.36716991662979126,
      "learning_rate": 5.533405537022845e-05,
      "loss": 0.3685,
      "step": 670
    },
    {
      "epoch": 1.5786419036564132,
      "grad_norm": 0.40236401557922363,
      "learning_rate": 5.3987019417258264e-05,
      "loss": 0.3661,
      "step": 680
    },
    {
      "epoch": 1.6018572257690076,
      "grad_norm": 0.3752015233039856,
      "learning_rate": 5.263706430927895e-05,
      "loss": 0.3647,
      "step": 690
    },
    {
      "epoch": 1.6250725478816017,
      "grad_norm": 0.3421303331851959,
      "learning_rate": 5.128517843581233e-05,
      "loss": 0.3688,
      "step": 700
    },
    {
      "epoch": 1.648287869994196,
      "grad_norm": 0.42321500182151794,
      "learning_rate": 4.993235160001874e-05,
      "loss": 0.3561,
      "step": 710
    },
    {
      "epoch": 1.6715031921067904,
      "grad_norm": 0.5263457894325256,
      "learning_rate": 4.857957429399788e-05,
      "loss": 0.3727,
      "step": 720
    },
    {
      "epoch": 1.6947185142193848,
      "grad_norm": 0.327847957611084,
      "learning_rate": 4.722783697358555e-05,
      "loss": 0.3597,
      "step": 730
    },
    {
      "epoch": 1.7179338363319792,
      "grad_norm": 0.37635695934295654,
      "learning_rate": 4.587812933317675e-05,
      "loss": 0.3714,
      "step": 740
    },
    {
      "epoch": 1.7411491584445735,
      "grad_norm": 0.4917539060115814,
      "learning_rate": 4.4531439581106295e-05,
      "loss": 0.3671,
      "step": 750
    },
    {
      "epoch": 1.7643644805571679,
      "grad_norm": 0.4084150791168213,
      "learning_rate": 4.3188753716117656e-05,
      "loss": 0.362,
      "step": 760
    },
    {
      "epoch": 1.787579802669762,
      "grad_norm": 0.40603727102279663,
      "learning_rate": 4.1851054805449393e-05,
      "loss": 0.3733,
      "step": 770
    },
    {
      "epoch": 1.8107951247823564,
      "grad_norm": 0.3848424255847931,
      "learning_rate": 4.051932226506797e-05,
      "loss": 0.3663,
      "step": 780
    },
    {
      "epoch": 1.8340104468949505,
      "grad_norm": 0.40094268321990967,
      "learning_rate": 3.9194531142573884e-05,
      "loss": 0.36,
      "step": 790
    },
    {
      "epoch": 1.8572257690075449,
      "grad_norm": 0.3636237382888794,
      "learning_rate": 3.787765140330636e-05,
      "loss": 0.3549,
      "step": 800
    },
    {
      "epoch": 1.8804410911201392,
      "grad_norm": 0.40122929215431213,
      "learning_rate": 3.656964722016875e-05,
      "loss": 0.3599,
      "step": 810
    },
    {
      "epoch": 1.9036564132327336,
      "grad_norm": 0.520938515663147,
      "learning_rate": 3.527147626769521e-05,
      "loss": 0.3587,
      "step": 820
    },
    {
      "epoch": 1.926871735345328,
      "grad_norm": 0.3677503764629364,
      "learning_rate": 3.3984089020875285e-05,
      "loss": 0.3557,
      "step": 830
    },
    {
      "epoch": 1.9500870574579223,
      "grad_norm": 0.6482582092285156,
      "learning_rate": 3.2708428059249436e-05,
      "loss": 0.3578,
      "step": 840
    },
    {
      "epoch": 1.9733023795705167,
      "grad_norm": 0.3872033357620239,
      "learning_rate": 3.144542737678568e-05,
      "loss": 0.3609,
      "step": 850
    },
    {
      "epoch": 1.9965177016831108,
      "grad_norm": 0.46505722403526306,
      "learning_rate": 3.019601169804216e-05,
      "loss": 0.3622,
      "step": 860
    },
    {
      "epoch": 2.019733023795705,
      "grad_norm": 0.3931904137134552,
      "learning_rate": 2.896109580111634e-05,
      "loss": 0.3394,
      "step": 870
    },
    {
      "epoch": 2.0429483459082993,
      "grad_norm": 0.5222058892250061,
      "learning_rate": 2.7741583847876818e-05,
      "loss": 0.3377,
      "step": 880
    },
    {
      "epoch": 2.0661636680208937,
      "grad_norm": 0.47460368275642395,
      "learning_rate": 2.6538368721967837e-05,
      "loss": 0.3398,
      "step": 890
    },
    {
      "epoch": 2.089378990133488,
      "grad_norm": 0.39276188611984253,
      "learning_rate": 2.5352331375071437e-05,
      "loss": 0.3317,
      "step": 900
    },
    {
      "epoch": 2.1125943122460824,
      "grad_norm": 0.44854536652565,
      "learning_rate": 2.4184340181905673e-05,
      "loss": 0.3395,
      "step": 910
    },
    {
      "epoch": 2.1358096343586768,
      "grad_norm": 0.5960031151771545,
      "learning_rate": 2.3035250304431206e-05,
      "loss": 0.3316,
      "step": 920
    },
    {
      "epoch": 2.159024956471271,
      "grad_norm": 0.5491344928741455,
      "learning_rate": 2.1905903065731974e-05,
      "loss": 0.3546,
      "step": 930
    },
    {
      "epoch": 2.1822402785838655,
      "grad_norm": 0.5473164319992065,
      "learning_rate": 2.079712533402808e-05,
      "loss": 0.3275,
      "step": 940
    },
    {
      "epoch": 2.20545560069646,
      "grad_norm": 0.6454873085021973,
      "learning_rate": 1.970972891727194e-05,
      "loss": 0.3342,
      "step": 950
    },
    {
      "epoch": 2.228670922809054,
      "grad_norm": 0.5565490126609802,
      "learning_rate": 1.86445099687713e-05,
      "loss": 0.3288,
      "step": 960
    },
    {
      "epoch": 2.251886244921648,
      "grad_norm": 0.6604729294776917,
      "learning_rate": 1.760224840427369e-05,
      "loss": 0.3354,
      "step": 970
    },
    {
      "epoch": 2.2751015670342425,
      "grad_norm": 0.4743017256259918,
      "learning_rate": 1.6583707330939775e-05,
      "loss": 0.335,
      "step": 980
    },
    {
      "epoch": 2.298316889146837,
      "grad_norm": 0.5073367357254028,
      "learning_rate": 1.5589632488623053e-05,
      "loss": 0.3326,
      "step": 990
    },
    {
      "epoch": 2.321532211259431,
      "grad_norm": 0.5301790833473206,
      "learning_rate": 1.462075170386556e-05,
      "loss": 0.3348,
      "step": 1000
    },
    {
      "epoch": 2.3447475333720256,
      "grad_norm": 0.5234692692756653,
      "learning_rate": 1.3677774357008899e-05,
      "loss": 0.3347,
      "step": 1010
    },
    {
      "epoch": 2.36796285548462,
      "grad_norm": 0.5394233465194702,
      "learning_rate": 1.2761390862810907e-05,
      "loss": 0.3246,
      "step": 1020
    },
    {
      "epoch": 2.3911781775972143,
      "grad_norm": 0.5631129145622253,
      "learning_rate": 1.1872272164948455e-05,
      "loss": 0.3285,
      "step": 1030
    },
    {
      "epoch": 2.4143934997098087,
      "grad_norm": 0.5693807005882263,
      "learning_rate": 1.1011069244775995e-05,
      "loss": 0.3283,
      "step": 1040
    },
    {
      "epoch": 2.437608821822403,
      "grad_norm": 0.5345635414123535,
      "learning_rate": 1.0178412644700092e-05,
      "loss": 0.335,
      "step": 1050
    },
    {
      "epoch": 2.460824143934997,
      "grad_norm": 0.505566418170929,
      "learning_rate": 9.374912006518466e-06,
      "loss": 0.3348,
      "step": 1060
    },
    {
      "epoch": 2.4840394660475913,
      "grad_norm": 0.7528557181358337,
      "learning_rate": 8.601155625061734e-06,
      "loss": 0.3373,
      "step": 1070
    },
    {
      "epoch": 2.5072547881601857,
      "grad_norm": 0.6896920800209045,
      "learning_rate": 7.857710017464737e-06,
      "loss": 0.3327,
      "step": 1080
    },
    {
      "epoch": 2.53047011027278,
      "grad_norm": 0.5579480528831482,
      "learning_rate": 7.145119508382664e-06,
      "loss": 0.3323,
      "step": 1090
    },
    {
      "epoch": 2.5536854323853744,
      "grad_norm": 0.5982835292816162,
      "learning_rate": 6.463905831455686e-06,
      "loss": 0.3459,
      "step": 1100
    },
    {
      "epoch": 2.5769007544979687,
      "grad_norm": 0.5257272720336914,
      "learning_rate": 5.814567747314048e-06,
      "loss": 0.3342,
      "step": 1110
    },
    {
      "epoch": 2.600116076610563,
      "grad_norm": 0.6235290765762329,
      "learning_rate": 5.197580678403075e-06,
      "loss": 0.325,
      "step": 1120
    },
    {
      "epoch": 2.623331398723157,
      "grad_norm": 0.6152024269104004,
      "learning_rate": 4.613396360895683e-06,
      "loss": 0.3294,
      "step": 1130
    },
    {
      "epoch": 2.646546720835752,
      "grad_norm": 0.8068195581436157,
      "learning_rate": 4.062442513947007e-06,
      "loss": 0.3221,
      "step": 1140
    },
    {
      "epoch": 2.6697620429483457,
      "grad_norm": 0.7409895658493042,
      "learning_rate": 3.5451225265335786e-06,
      "loss": 0.3415,
      "step": 1150
    },
    {
      "epoch": 2.69297736506094,
      "grad_norm": 0.5194656252861023,
      "learning_rate": 3.0618151621061466e-06,
      "loss": 0.3329,
      "step": 1160
    },
    {
      "epoch": 2.7161926871735345,
      "grad_norm": 0.5628031492233276,
      "learning_rate": 2.6128742812723704e-06,
      "loss": 0.3232,
      "step": 1170
    },
    {
      "epoch": 2.739408009286129,
      "grad_norm": 0.4756529629230499,
      "learning_rate": 2.198628582712642e-06,
      "loss": 0.3333,
      "step": 1180
    },
    {
      "epoch": 2.762623331398723,
      "grad_norm": 0.5453629493713379,
      "learning_rate": 1.819381362518463e-06,
      "loss": 0.3323,
      "step": 1190
    },
    {
      "epoch": 2.7858386535113175,
      "grad_norm": 0.5220151543617249,
      "learning_rate": 1.4754102921297364e-06,
      "loss": 0.3275,
      "step": 1200
    },
    {
      "epoch": 2.809053975623912,
      "grad_norm": 0.4888245463371277,
      "learning_rate": 1.1669672150335486e-06,
      "loss": 0.3353,
      "step": 1210
    },
    {
      "epoch": 2.832269297736506,
      "grad_norm": 0.5215814709663391,
      "learning_rate": 8.942779623732578e-07,
      "loss": 0.3309,
      "step": 1220
    },
    {
      "epoch": 2.8554846198491006,
      "grad_norm": 0.570662796497345,
      "learning_rate": 6.57542187602872e-07,
      "loss": 0.3353,
      "step": 1230
    },
    {
      "epoch": 2.8786999419616945,
      "grad_norm": 0.6880992650985718,
      "learning_rate": 4.5693322030782584e-07,
      "loss": 0.337,
      "step": 1240
    },
    {
      "epoch": 2.901915264074289,
      "grad_norm": 0.5224773287773132,
      "learning_rate": 2.9259793929921063e-07,
      "loss": 0.3365,
      "step": 1250
    },
    {
      "epoch": 2.9251305861868833,
      "grad_norm": 0.5711934566497803,
      "learning_rate": 1.6465666507425315e-07,
      "loss": 0.3482,
      "step": 1260
    },
    {
      "epoch": 2.9483459082994776,
      "grad_norm": 0.5607360005378723,
      "learning_rate": 7.320307172190011e-08,
      "loss": 0.3352,
      "step": 1270
    },
    {
      "epoch": 2.971561230412072,
      "grad_norm": 0.5901493430137634,
      "learning_rate": 1.830411833795287e-08,
      "loss": 0.338,
      "step": 1280
    },
    {
      "epoch": 2.9947765525246663,
      "grad_norm": 0.674752950668335,
      "learning_rate": 0.0,
      "loss": 0.3327,
      "step": 1290
    },
    {
      "epoch": 2.9947765525246663,
      "step": 1290,
      "total_flos": 7.634069876839956e+17,
      "train_loss": 0.37873414856518883,
      "train_runtime": 17115.8377,
      "train_samples_per_second": 0.604,
      "train_steps_per_second": 0.075
    }
  ],
  "logging_steps": 10,
  "max_steps": 1290,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7.634069876839956e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
