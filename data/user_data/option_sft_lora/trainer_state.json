{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9877149877149876,
  "eval_steps": 500,
  "global_step": 456,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06552006552006552,
      "grad_norm": 32.98576736450195,
      "learning_rate": 2.173913043478261e-05,
      "loss": 11.6902,
      "step": 10
    },
    {
      "epoch": 0.13104013104013104,
      "grad_norm": 18.63536262512207,
      "learning_rate": 4.347826086956522e-05,
      "loss": 8.1148,
      "step": 20
    },
    {
      "epoch": 0.19656019656019655,
      "grad_norm": 3.895872116088867,
      "learning_rate": 6.521739130434783e-05,
      "loss": 4.8713,
      "step": 30
    },
    {
      "epoch": 0.2620802620802621,
      "grad_norm": 1.7253592014312744,
      "learning_rate": 8.695652173913044e-05,
      "loss": 4.3736,
      "step": 40
    },
    {
      "epoch": 0.3276003276003276,
      "grad_norm": 6.611828804016113,
      "learning_rate": 9.997651675955466e-05,
      "loss": 4.3022,
      "step": 50
    },
    {
      "epoch": 0.3931203931203931,
      "grad_norm": 0.8059982657432556,
      "learning_rate": 9.9712583567233e-05,
      "loss": 4.2008,
      "step": 60
    },
    {
      "epoch": 0.45864045864045866,
      "grad_norm": 5.049437999725342,
      "learning_rate": 9.915691716719898e-05,
      "loss": 4.1383,
      "step": 70
    },
    {
      "epoch": 0.5241605241605242,
      "grad_norm": 4.13352108001709,
      "learning_rate": 9.831277843083904e-05,
      "loss": 4.2565,
      "step": 80
    },
    {
      "epoch": 0.5896805896805897,
      "grad_norm": 5.3088483810424805,
      "learning_rate": 9.718512109991514e-05,
      "loss": 4.1145,
      "step": 90
    },
    {
      "epoch": 0.6552006552006552,
      "grad_norm": 2.4963080883026123,
      "learning_rate": 9.578056271603837e-05,
      "loss": 4.0507,
      "step": 100
    },
    {
      "epoch": 0.7207207207207207,
      "grad_norm": 3.074720859527588,
      "learning_rate": 9.410734578630343e-05,
      "loss": 4.0735,
      "step": 110
    },
    {
      "epoch": 0.7862407862407862,
      "grad_norm": 2.3294503688812256,
      "learning_rate": 9.217528941297941e-05,
      "loss": 4.0901,
      "step": 120
    },
    {
      "epoch": 0.8517608517608518,
      "grad_norm": 2.7664546966552734,
      "learning_rate": 8.999573167111348e-05,
      "loss": 4.1255,
      "step": 130
    },
    {
      "epoch": 0.9172809172809173,
      "grad_norm": 0.18713150918483734,
      "learning_rate": 8.758146307219792e-05,
      "loss": 4.0723,
      "step": 140
    },
    {
      "epoch": 0.9828009828009828,
      "grad_norm": 5.085873603820801,
      "learning_rate": 8.494665150436288e-05,
      "loss": 4.0603,
      "step": 150
    },
    {
      "epoch": 1.0483210483210483,
      "grad_norm": 0.2716372013092041,
      "learning_rate": 8.210675908957512e-05,
      "loss": 4.0293,
      "step": 160
    },
    {
      "epoch": 1.1138411138411137,
      "grad_norm": 0.27150699496269226,
      "learning_rate": 7.907845144575829e-05,
      "loss": 4.0658,
      "step": 170
    },
    {
      "epoch": 1.1793611793611793,
      "grad_norm": 0.612865686416626,
      "learning_rate": 7.587949988631982e-05,
      "loss": 3.9716,
      "step": 180
    },
    {
      "epoch": 1.244881244881245,
      "grad_norm": 0.5590961575508118,
      "learning_rate": 7.252867713101771e-05,
      "loss": 4.0193,
      "step": 190
    },
    {
      "epoch": 1.3104013104013104,
      "grad_norm": 2.7736284732818604,
      "learning_rate": 6.904564714017614e-05,
      "loss": 3.9762,
      "step": 200
    },
    {
      "epoch": 1.375921375921376,
      "grad_norm": 0.045610036700963974,
      "learning_rate": 6.545084971874738e-05,
      "loss": 4.0369,
      "step": 210
    },
    {
      "epoch": 1.4414414414414414,
      "grad_norm": 7.326547622680664,
      "learning_rate": 6.17653805674087e-05,
      "loss": 4.0558,
      "step": 220
    },
    {
      "epoch": 1.506961506961507,
      "grad_norm": 0.03631988912820816,
      "learning_rate": 5.801086748460255e-05,
      "loss": 3.9724,
      "step": 230
    },
    {
      "epoch": 1.5724815724815726,
      "grad_norm": 0.09685616940259933,
      "learning_rate": 5.4209343446015356e-05,
      "loss": 4.0618,
      "step": 240
    },
    {
      "epoch": 1.638001638001638,
      "grad_norm": 8.057401657104492,
      "learning_rate": 5.038311730631509e-05,
      "loss": 4.0374,
      "step": 250
    },
    {
      "epoch": 1.7035217035217034,
      "grad_norm": 0.04423370957374573,
      "learning_rate": 4.6554642881921467e-05,
      "loss": 3.9866,
      "step": 260
    },
    {
      "epoch": 1.769041769041769,
      "grad_norm": 0.05686883628368378,
      "learning_rate": 4.2746387183082755e-05,
      "loss": 4.0363,
      "step": 270
    },
    {
      "epoch": 1.8345618345618346,
      "grad_norm": 4.671321392059326,
      "learning_rate": 3.898069856852607e-05,
      "loss": 4.0407,
      "step": 280
    },
    {
      "epoch": 1.9000819000819,
      "grad_norm": 0.2752295732498169,
      "learning_rate": 3.5279675596401846e-05,
      "loss": 3.9854,
      "step": 290
    },
    {
      "epoch": 1.9656019656019657,
      "grad_norm": 7.095087051391602,
      "learning_rate": 3.166503734115761e-05,
      "loss": 4.1491,
      "step": 300
    },
    {
      "epoch": 2.031122031122031,
      "grad_norm": 0.039090175181627274,
      "learning_rate": 2.815799593737285e-05,
      "loss": 3.9749,
      "step": 310
    },
    {
      "epoch": 2.0966420966420967,
      "grad_norm": 0.05902879312634468,
      "learning_rate": 2.4779132098518675e-05,
      "loss": 3.9655,
      "step": 320
    },
    {
      "epoch": 2.1621621621621623,
      "grad_norm": 0.06091640517115593,
      "learning_rate": 2.154827434114765e-05,
      "loss": 3.9649,
      "step": 330
    },
    {
      "epoch": 2.2276822276822275,
      "grad_norm": 0.10832393169403076,
      "learning_rate": 1.84843826232741e-05,
      "loss": 3.9615,
      "step": 340
    },
    {
      "epoch": 2.293202293202293,
      "grad_norm": 0.017523178830742836,
      "learning_rate": 1.560543707980152e-05,
      "loss": 3.9751,
      "step": 350
    },
    {
      "epoch": 2.3587223587223587,
      "grad_norm": 0.035056788474321365,
      "learning_rate": 1.2928332507941342e-05,
      "loss": 3.9612,
      "step": 360
    },
    {
      "epoch": 2.4242424242424243,
      "grad_norm": 0.5025389194488525,
      "learning_rate": 1.0468779221825103e-05,
      "loss": 3.9631,
      "step": 370
    },
    {
      "epoch": 2.48976248976249,
      "grad_norm": 0.029997488483786583,
      "learning_rate": 8.241210858134108e-06,
      "loss": 3.9646,
      "step": 380
    },
    {
      "epoch": 2.555282555282555,
      "grad_norm": 0.028233304619789124,
      "learning_rate": 6.258699673780083e-06,
      "loss": 3.9606,
      "step": 390
    },
    {
      "epoch": 2.6208026208026207,
      "grad_norm": 0.04272719472646713,
      "learning_rate": 4.532879832703757e-06,
      "loss": 3.9762,
      "step": 400
    },
    {
      "epoch": 2.6863226863226863,
      "grad_norm": 0.0359775647521019,
      "learning_rate": 3.0738791319746606e-06,
      "loss": 3.9918,
      "step": 410
    },
    {
      "epoch": 2.751842751842752,
      "grad_norm": 0.07375090569257736,
      "learning_rate": 1.8902595678507829e-06,
      "loss": 3.9856,
      "step": 420
    },
    {
      "epoch": 2.8173628173628176,
      "grad_norm": 0.172682985663414,
      "learning_rate": 9.889670905800397e-07,
      "loss": 3.9627,
      "step": 430
    },
    {
      "epoch": 2.8828828828828827,
      "grad_norm": 0.05687214806675911,
      "learning_rate": 3.752908428022506e-07,
      "loss": 3.9778,
      "step": 440
    },
    {
      "epoch": 2.9484029484029484,
      "grad_norm": 0.04339916631579399,
      "learning_rate": 5.2832120757007054e-08,
      "loss": 4.0008,
      "step": 450
    },
    {
      "epoch": 2.9877149877149876,
      "step": 456,
      "total_flos": 1.6639315227898675e+17,
      "train_loss": 4.318926765207658,
      "train_runtime": 3516.5631,
      "train_samples_per_second": 1.042,
      "train_steps_per_second": 0.13
    }
  ],
  "logging_steps": 10,
  "max_steps": 456,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.6639315227898675e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
